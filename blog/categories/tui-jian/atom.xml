<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 推荐 | 刚刚在线]]></title>
  <link href="http://www.superqq.com/blog/categories/tui-jian/atom.xml" rel="self"/>
  <link href="http://www.superqq.com/"/>
  <updated>2015-12-09T23:39:40+08:00</updated>
  <id>http://www.superqq.com/</id>
  <author>
    <name><![CDATA[李刚]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[关于启用 HTTPS 的一些经验分享]]></title>
    <link href="http://www.superqq.com/blog/2015/12/08/some-experiences-https/"/>
    <updated>2015-12-08T21:54:20+08:00</updated>
    <id>http://www.superqq.com/blog/2015/12/08/some-experiences-https</id>
    <content type="html"><![CDATA[<p><img src="http://images.90159.com/12/https.jpg" alt="https" /></p>

<p>随着国内网络环境的持续恶化，各种篡改和劫持层出不穷，越来越多的网站选择了全站 HTTPS。HTTPS 通过 TLS 层和证书机制提供了内容加密、身份认证和数据完整性三大功能，可以有效防止数据被查看或篡改，以及防止中间人冒充。本文分享一些启用 HTTPS 过程中的经验，重点是如何与一些新出的安全规范配合使用。至于 HTTPS 的部署及优化，之前写过很多，本文不重复了。</p>

<!--more-->


<h2>理解 Mixed Content</h2>

<p>HTTPS 网页中加载的 HTTP 资源被称之为 Mixed Content(混合内容)，不同浏览器对 Mixed Content 有不一样的处理规则。</p>

<h2>早期的 IE</h2>

<p>早期的 IE 在发现 Mixed Content 请求时，会弹出「是否只查看安全传送的网页内容?」这样一个模态对话框，一旦用户选择「是」，所有 Mixed Content 资源都不会加载;选择「否」，所有资源都加载。</p>

<h2>比较新的 IE</h2>

<p>比较新的 IE 将模态对话框改为页面底部的提示条，没有之前那么干扰用户。而且默认会加载图片类 Mixed Content，其它如 JavaScript、CSS 等资源还是会根据用户选择来决定是否加载。</p>

<h2>现代浏览器</h2>

<p>现代浏览器(Chrome、Firefox、Safari、Microsoft Edge)，基本上都遵守了 W3C 的 Mixed Content 规范，将 Mixed Content 分为Optionally-blockable 和 Blockable 两类：</p>

<p>Optionally-blockable 类 Mixed Content 包含那些危险较小，即使被中间人篡改也无大碍的资源。现代浏览器默认会加载这类资源，同时会在控制台打印警告信息。这类资源包括：</p>

<pre><code>通过  标签加载的图片(包括 SVG 图片);

通过 &lt;img&gt; 标签加载的图片（包括 SVG 图片）；

通过 &lt;video&gt; / &lt;audio&gt; 和 &lt;source&gt; 标签加载的视频或音频；

预读的（Prefetched）资源；
</code></pre>

<h2>预读的(Prefetched)资源;</h2>

<p>除此之外所有的 Mixed Content 都是 Blockable，浏览器必须禁止加载这类资源。所以现代浏览器中，对于 HTTPS 页面中的 JavaScript、CSS 等 HTTP 资源，一律不加载，直接在控制台打印错误信息。</p>

<h2>移动浏览器</h2>

<p>前面所说都是桌面浏览器的行为，移动端情况比较复杂，当前大部分移动浏览器默认都允许加载 Mixed Content。也就是说，对于移动浏览器来说，HTTPS 中的 HTTP 资源，无论是图片还是 JavaScript、CSS，默认都会加载。</p>

<p>一般选择了全站 HTTPS，就要避免出现 Mixed Content，页面所有资源请求都走 HTTPS 协议才能保证所有平台所有浏览器下都没有问题。</p>

<h2>合理使用 CSP</h2>

<p>CSP，全称是 Content Security Policy，它有非常多的指令，用来实现各种各样与页面内容安全相关的功能。</p>

<pre><code>block-all-mixed-content
</code></pre>

<p>前面说过，对于 HTTPS 中的图片等 Optionally-blockable 类 HTTP 资源，现代浏览器默认会加载。图片类资源被劫持，通常不会有太大的问题，但也有一些风险，例如很多网页按钮是用图片实现的，中间人把这些图片改掉，也会干扰用户使用。</p>

<p>通过 CSP 的 block-all-mixed-content 指令，可以让页面进入对混合内容的严格检测(Strict Mixed Content Checking)模式。在这种模式下，所有非 HTTPS 资源都不允许加载。跟其它所有 CSP 规则一样，可以通过以下两种方式启用这个指令：</p>

<h2>HTTP 响应头方式：</h2>

<pre><code>Content-Security-Policy: block-all-mixed-content 
</code></pre>

<p><meta>标签方式：</p>

<pre><code>&lt;meta http-equiv="Content-Security-Policy" content="block-all-mixed-content"&gt; 


upgrade-insecure-requests
</code></pre>

<p>历史悠久的大站在往 HTTPS 迁移的过程中，工作量往往非常巨大，尤其是将所有资源都替换为 HTTPS 这一步，很容易产生疏漏。即使所有代码都确认没有问题，很可能某些从数据库读取的字段中还存在 HTTP 链接。</p>

<p>而通过 upgrade-insecure-requests 这个 CSP 指令，可以让浏览器帮忙做这个转换。启用这个策略后，有两个变化：</p>

<pre><code>页面所有 HTTP 资源，会被替换为 HTTPS 地址再发起请求;

页面所有站内链接，点击后会被替换为 HTTPS 地址再跳转;
</code></pre>

<p>跟其它所有 CSP 规则一样，这个指令也有两种方式来启用，具体格式请参考上一节。需要注意的是 upgrade-insecure-requests 只替换协议部分，所以只适用于 HTTP/HTTPS 域名和路径完全一致的场景。</p>

<h2>合理使用 HSTS</h2>

<p>在网站全站 HTTPS 后，如果用户手动敲入网站的 HTTP 地址，或者从其它地方点击了网站的 HTTP 链接，依赖于服务端 301/302 跳转才能使用 HTTPS 服务。而第一次的 HTTP 请求就有可能被劫持，导致请求无法到达服务器，从而构成 HTTPS 降级劫持。</p>

<h2>HSTS 基本使用</h2>

<p>这个问题可以通过 HSTS(HTTP Strict Transport Security，RFC6797)来解决。HSTS 是一个响应头，格式如下：</p>

<pre><code>Strict-Transport-Security: max-age=expireTime [; includeSubDomains] [; preload] 
</code></pre>

<p>max-age，单位是秒，用来告诉浏览器在指定时间内，这个网站必须通过 HTTPS 协议来访问。也就是对于这个网站的 HTTP 地址，浏览器需要先在本地替换为 HTTPS 之后再发送请求。</p>

<p>includeSubDomains，可选参数，如果指定这个参数，表明这个网站所有子域名也必须通过 HTTPS 协议来访问。</p>

<p>preload，可选参数，后面再介绍它的作用。</p>

<p>HSTS 这个响应头只能用于 HTTPS 响应;网站必须使用默认的 443 端口;必须使用域名，不能是 IP。而且启用 HSTS 之后，一旦网站证书错误，用户无法选择忽略。</p>

<p>HSTS Preload List</p>

<p>可以看到 HSTS 可以很好的解决 HTTPS 降级攻击，但是对于 HSTS 生效前的首次 HTTP 请求，依然无法避免被劫持。浏览器厂商们为了解决这个问题，提出了 HSTS Preload List 方案：内置一份列表，对于列表中的域名，即使用户之前没有访问过，也会使用 HTTPS 协议;列表可以定期更新。</p>

<p>目前这个 Preload List 由 Google Chrome 维护，Chrome、Firefox、Safari、IE 11 和 Microsoft Edge 都在使用。如果要想把自己的域名加进这个列表，首先需要满足以下条件：</p>

<pre><code>拥有合法的证书(如果使用 SHA-1 证书，过期时间必须早于 2016 年);

将所有 HTTP 流量重定向到 HTTPS;

确保所有子域名都启用了 HTTPS;

输出 HSTS 响应头：

max-age 不能低于 18 周(10886400 秒);

必须指定 includeSubdomains 参数;

必须指定 preload 参数;
</code></pre>

<p>即便满足了上述所有条件，也不一定能进入 HSTS Preload Lis。通过 Chrome 的 chrome://net-internals/#hsts 工具，可以查询某个网站是否在 Preload List 之中，还可以手动把某个域名加到本机 Preload List。</p>

<p>对于 HSTS 以及 HSTS Preload List，我的建议是只要你不能确保永远提供 HTTPS 服务，就不要启用。因为一旦 HSTS 生效，你再想把网站重定向为 HTTP，之前的老用户会被无限重定向，唯一的办法是换新域名。</p>

<h2>CDN 安全</h2>

<p>对于大站来说，全站迁移到 HTTPS 后还是得用 CDN，只是必须选择支持 HTTPS 的 CDN 了。如果使用第三方 CDN，安全方面有一些需要考虑的地方。</p>

<h2>合理使用 SRI</h2>

<p>HTTPS 可以防止数据在传输中被篡改，合法的证书也可以起到验证服务器身份的作用，但是如果 CDN 服务器被入侵，导致静态文件在服务器上被篡改，HTTPS 也无能为力。</p>

<p>W3C 的 SRI(Subresource Integrity)规范可以用来解决这个问题。SRI 通过在页面引用资源时指定资源的摘要签名，来实现让浏览器验证资源是否被篡改的目的。只要页面不被篡改，SRI 策略就是可靠的。</p>

<p>SRI 并不是 HTTPS 专用，但如果主页面被劫持，攻击者可以轻松去掉资源摘要，从而失去浏览器的 SRI 校验机制。</p>

<h2>了解 Keyless SSL</h2>

<p>另外一个问题是，在使用第三方 CDN 的 HTTPS 服务时，如果要使用自己的域名，需要把对应的证书私钥给第三方，这也是一件风险很高的事情。</p>

<p>CloudFlare 公司针对这种场景研发了 Keyless SSL 技术。你可以不把证书私钥给第三方，改为提供一台实时计算的 Key Server 即可。CDN 要用到私钥时，通过加密通道将必要的参数传给 Key Server，由 Key Server 算出结果并返回即可。整个过程中，私钥都保管在自己的 Key Server 之中，不会暴露给第三方。</p>

<p>CloudFlare 的这套机制已经开源，如需了解详情，可以查看他们官方博客的这篇文章：Keyless SSL: The Nitty Gritty Technical Details。</p>

<p>好了，本文先就写到这里，需要注意的是本文提到的 CSP、HSTS 以及 SRI 等策略都只有最新的浏览器才支持，详细的支持度可以去 CanIUse 查。切换到 HTTPS 之后，在性能优化上有很多新工作要做，这部分内容我在之前的博客中写过很多，这里不再重复，只说最重要的一点：既然都 HTTPS 了，赶紧上 HTTP/2 才是正道。</p>

<p>内容来源：Jerry Qu的小站</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为自己的应用配备上 3D Touch 功能]]></title>
    <link href="http://www.superqq.com/blog/2015/10/31/app-touch-3d-function/"/>
    <updated>2015-10-31T10:35:24+08:00</updated>
    <id>http://www.superqq.com/blog/2015/10/31/app-touch-3d-function</id>
    <content type="html"><![CDATA[<p>随着 iPhone 6s 以及 iPhone 6s Plus 的发布，开发者们现在就可以为自己的应用配备上 3D Touch 功能了，从而给界面交互方式开启一个新的维度。</p>

<p>正如苹果所言，开发者可以通过非常简单的 API 来使用 3D Touch ，从根本上来说，也就是 UITouch 的一个简单的新属性。</p>

<pre><code>override func touchesBegan(touches: Set&lt;UITouch&gt;, withEvent event: UIEvent?) {
     guard let touch = touches.first else { return }
     if traitCollection.forceTouchCapability == .Available {
        println("Touch pressure is \(touch.force), maximum possible force is \(touch.maximumPossibleForce)")
     }
}
</code></pre>

<p>这个新的 API 可以让应用发挥出巨大的潜力，比如说游戏中的额外控制选项、绘图应用中的细粒度(fine-grained)控制，甚至是用来替代我们在 iOS 设备中使用过的长按操作(tap-and-hold)的极佳选择。</p>

<p>除了 UITouch 中新增的 API 外，苹果还为应用提供了两个用来增加3D Touch 功能的类集：UIPreviewAction 和 UIApplicationShortcutItem。</p>

<p>UIPreviewAction允许开发者在用户使用 3D Touch 功能触控一个 UI 元素的时候，快速地在一个新的预览窗口中显示某些内容。这种快速浏览应用特定内容的方式真的非常棒，比如说我们可以快速预览邮件信息、照片，甚至是网页内容，而无需弹出一个完整的视图控制器。</p>

<p>UIApplicationShortcutItem对象能够让 iOS 主屏幕激活一项令人惊叹的新特性。当用户使用 3D Touch 按下某个应用的图标时，一个选项列表就会被弹出，允许用户快速跳转至应用的特定部分，或者执行某项应用内的功能。</p>

<p><img src="http://images.90159.com/10/touch.jpg" alt="touch" /></p>

<p>总而言之，3D Touch 的引入给 iOS 设备解锁了一个全新的交互方式，并且将会给接下来的 iOS 应用带来新一代的创新。关于3D Touch 的实例代码和相关信息可以在苹果开发者网站的3D Touch网页上找到，祝你好运！</p>

<p>作者：Tim Oliver
@TimOliverAU — iComics创始人</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[五个案例让你明白GCD死锁]]></title>
    <link href="http://www.superqq.com/blog/2015/10/16/five-case-know-gcd/"/>
    <updated>2015-10-16T20:29:42+08:00</updated>
    <id>http://www.superqq.com/blog/2015/10/16/five-case-know-gcd</id>
    <content type="html"><![CDATA[<pre><code>作者：brighttj（@saitjr

网址：http://www.brighttj.com/ios/ios-gcd-deadlock.html
</code></pre>

<p>死锁一直都是在使用多线程时，需要注意的一个问题。以前对同步、异步，串行、并行只有一个模糊的概念，想想也是时候整理一下了。再看看之前的博客，已经很久没有干货了【说得好像之前有干货一样】，所以，这篇博客，我尽最大努力，也借鉴了很多其他博客中的例子，来讲解GCD死锁问题。</p>

<p>环境信息：</p>

<p>Mac OS X 10.10.5</p>

<p>Xcode 6.4</p>

<p>iOS  8.4</p>

<h2>串行与并行</h2>

<p>在使用GCD的时候，我们会把需要处理的任务放到Block中，然后将任务追加到相应的队列里面，这个队列，叫做Dispatch Queue。然而，存在于两种Dispatch Queue，一种是要等待上一个执行完，再执行下一个的Serial Dispatch Queue，这叫做串行队列；另一种，则是不需要上一个执行完，就能执行下一个的Concurrent Dispatch Queue，叫做并行队列。这两种，均遵循FIFO原则。</p>

<pre><code>举一个简单的例子，在三个任务中输出1、2、3，串行队列输出是有序的1、2、3，但是并行队列的先后顺序就不一定了。
</code></pre>

<p>那么，并行队列又是怎么在执行呢？</p>

<p>虽然可以同时多个任务的处理，但是并行队列的处理量，还是要根据当前系统状态来。如果当前系统状态最多处理2个任务，那么1、2会排在前面，3什么时候操作，就看1或者2谁先完成，然后3接在后面。</p>

<p>串行和并行就简单说到这里，关于它们的技术点其实还有很多，可以自行了解。</p>

<h2>同步与异步</h2>

<p>串行与并行针对的是队列，而同步与异步，针对的则是线程。最大的区别在于，同步线程要阻塞当前线程，必须要等待同步线程中的任务执行完，返回以后，才能继续执行下一任务；而异步线程则是不用等待。</p>

<p>仅凭这几句话还是很难理解，所以之后准备了很多案例，可以边分析边理解。</p>

<!--more-->


<h2>GCD API</h2>

<p>GCD API很多，这里仅介绍本文用到的。</p>

<ol>
<li><p>系统标准提供的两个队列</p>

<pre><code> // 全局队列，也是一个并行队列

 dispatch_get_global_queue 

 // 主队列，在主线程中运行，因为主线程只有一个，所以这是一个串行队列

 dispatch_get_main_queue 
</code></pre></li>
<li><p>除此之外，还可以自己生成队列</p>

<pre><code> // 从DISPATCH_QUEUE_SERIAL看出，这是串行队列

 dispatch_queue_create("com.demo.serialQueue", DISPATCH_QUEUE_SERIAL) 

 // 同理，这是一个并行队列

 dispatch_queue_create("com.demo.concurrentQueue", DISPATCH_QUEUE_CONCURRENT) 
</code></pre></li>
</ol>


<p>接下来是同步与异步线程的创建：</p>

<pre><code>dispatch_sync(..., ^(block)) // 同步线程

dispatch_async(..., ^(block)) // 异步线程
</code></pre>

<h2>案例与分析</h2>

<p>假设你已经基本了解了上面提到的知识，接下来进入案例讲解阶段。</p>

<h2>案例一：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_sync(dispatch_get_main_queue(), ^{

    NSLog(@"2"); // 任务2

});

NSLog(@"3"); // 任务3
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1
</code></pre>

<p>分析：</p>

<pre><code>dispatch_sync表示是一个同步线程；

dispatch_get_main_queue表示运行在主线程中的主队列；

任务2是同步线程的任务。
</code></pre>

<p>首先执行任务1，这是肯定没问题的，只是接下来，程序遇到了同步线程，那么它会进入等待，等待任务2执行完，然后执行任务3。但这是队列，有任务来，当然会将任务加到队尾，然后遵循FIFO原则执行任务。那么，现在任务2就会被加到最后，任务3排在了任务2前面，问题来了：</p>

<pre><code>任务3要等任务2执行完才能执行，任务2由排在任务3后面，意味着任务2要在任务3执行完才能执行，所以他们进入了互相等待的局面。【既然这样，那干脆就卡在这里吧】这就是死锁。
</code></pre>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-1.png" alt="deadlock" /></p>

<h2>案例二：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_sync(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0), ^{

    NSLog(@"2"); // 任务2

});

NSLog(@"3"); // 任务3
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

2

3
</code></pre>

<p>分析：</p>

<p>首先执行任务1，接下来会遇到一个同步线程，程序会进入等待。等待任务2执行完成以后，才能继续执行任务3。从dispatch_get_global_queue可以看出，任务2被加入到了全局的并行队列中，当并行队列执行完任务2以后，返回到主队列，继续执行任务3。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-2.png" alt="2" /></p>

<h2>案例三：</h2>

<pre><code>dispatch_queue_t queue = dispatch_queue_create("com.demo.serialQueue", DISPATCH_QUEUE_SERIAL);

NSLog(@"1"); // 任务1

dispatch_async(queue, ^{

    NSLog(@"2"); // 任务2

    dispatch_sync(queue, ^{  

        NSLog(@"3"); // 任务3

    });

    NSLog(@"4"); // 任务4

});

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

5

2

// 5和2的顺序不一定
</code></pre>

<p>分析：</p>

<p>这个案例没有使用系统提供的串行或并行队列，而是自己通过dispatch_queue_create函数创建了一个DISPATCH_QUEUE_SERIAL的串行队列。</p>

<pre><code>执行任务1；

遇到异步线程，将【任务2、同步线程、任务4】加入串行队列中。因为是异步线程，所以在主线程中的任务5不必等待异步线程中的所有任务完成；

因为任务5不必等待，所以2和5的输出顺序不能确定；

任务2执行完以后，遇到同步线程，这时，将任务3加入串行队列；

又因为任务4比任务3早加入串行队列，所以，任务3要等待任务4完成以后，才能执行。但是任务3所在的同步线程会阻塞，所以任务4必须等任务3执行完以后再执行。这就又陷入了无限的等待中，造成死锁。
</code></pre>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-3.png" alt="3" /></p>

<h2>案例四：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_async(dispatch_get_global_queue(0, 0), ^{

    NSLog(@"2"); // 任务2

    dispatch_sync(dispatch_get_main_queue(), ^{

        NSLog(@"3"); // 任务3

    });

    NSLog(@"4"); // 任务4

});

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

2

5

3

4

// 5和2的顺序不一定
</code></pre>

<p>分析：</p>

<p>首先，将【任务1、异步线程、任务5】加入Main Queue中，异步线程中的任务是：【任务2、同步线程、任务4】。</p>

<p>所以，先执行任务1，然后将异步线程中的任务加入到Global Queue中，因为异步线程，所以任务5不用等待，结果就是2和5的输出顺序不一定。</p>

<p>然后再看异步线程中的任务执行顺序。任务2执行完以后，遇到同步线程。将同步线程中的任务加入到Main Queue中，这时加入的任务3在任务5的后面。</p>

<p>当任务3执行完以后，没有了阻塞，程序继续执行任务4。</p>

<p>从以上的分析来看，得到的几个结果：1最先执行；2和5顺序不一定；4一定在3后面。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-4.png" alt="4" /></p>

<h2>案例五：</h2>

<pre><code>dispatch_async(dispatch_get_global_queue(0, 0), ^{

    NSLog(@"1"); // 任务1

    dispatch_sync(dispatch_get_main_queue(), ^{

        NSLog(@"2"); // 任务2

    });

    NSLog(@"3"); // 任务3

});

NSLog(@"4"); // 任务4

while (1) {

}

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

4

// 1和4的顺序不一定
</code></pre>

<p>分析：</p>

<p>和上面几个案例的分析类似，先来看看都有哪些任务加入了Main Queue：【异步线程、任务4、死循环、任务5】。</p>

<p>在加入到Global Queue异步线程中的任务有：【任务1、同步线程、任务3】。</p>

<p>第一个就是异步线程，任务4不用等待，所以结果任务1和任务4顺序不一定。</p>

<p>任务4完成后，程序进入死循环，Main Queue阻塞。但是加入到Global Queue的异步线程不受影响，继续执行任务1后面的同步线程。</p>

<p>同步线程中，将任务2加入到了主线程，并且，任务3等待任务2完成以后才能执行。这时的主线程，已经被死循环阻塞了。所以任务2无法执行，当然任务3也无法执行，在死循环后的任务5也不会执行。</p>

<p>最终，只能得到1和4顺序不定的结果。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-5.png" alt="5" /></p>

<h2>参考</h2>

<pre><code>http://www.jianshu.com/p/0b0d9b1f1f19

http://www.cnblogs.com/tangbinblog/p/4133481.html
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关 XcodeGhost 的问题和解答]]></title>
    <link href="http://www.superqq.com/blog/2015/09/24/apple-xcodeghost-answer/"/>
    <updated>2015-09-24T00:09:03+08:00</updated>
    <id>http://www.superqq.com/blog/2015/09/24/apple-xcodeghost-answer</id>
    <content type="html"><![CDATA[<p><strong>我听说了由 XcodeGhost 开发的恶意 app — 这是怎么回事？</strong></p>

<p>我们一直建议开发者使用由我们提供的免费、安全的工具，包括 Xcode，从而确保他们为 App Store 的用户创造出安全的 app。一些开发者下载了已被恶意软件感染的盗版 Xcode，由此开发的 app 也同样受到感染。</p>

<p>Apple 特意使用诸如 Gatekeeper 等技术，以防止安装从非 App Store 渠道下载的应用程序，和 / 或安装包括 Xcode 在内的未签名的应用程序。当开发者为了能安装类似 XcodeGhost 等恶意程序时，这些保护措施会被刻意地禁用。</p>

<p>作为 Apple 向开发者提供的业界先进工具之一，以下措施可以确保软件未被篡改：</p>

<pre><code>Xcode app 有 Apple 的代码签名。
从 Mac App Store 下载 Xcode 时，开发者的电脑系统自动对 Xcode 的代码签名会进行检查和验证。
从 Apple Developer Program 网站下载 Xcode 时，只要 Gatekeeper 没有被禁用，默认开发者的电脑系统对 Xcode 代码签名自动进行检查和验证。
</code></pre>

<h3>为什么开发者会不顾用户的安全下载盗版软件？</h3>

<p>为了更快下载我们的开发者工具，开发者有时会从其他非 Apple 站点搜寻。</p>

<h3>这会对我有什么影响吗？如何得知我的设备是否受到了影响？</h3>

<p>我们目前没有任何信息表明这些恶意软件与任何恶意事件相关，也没有信息表明这些软件被使用在传播任何个人身份信息的用途上。</p>

<p>我们目前没有看到任何客户个人身份信息受到影响，而且代码无法通过用户身份请求来获取 iCloud 或其他服务的密码。</p>

<p>只要一经发现这些 app 有可能通过恶意代码开发，我们就对其进行下架处理。开发者们正在快速更新他们的 app，以便用户使用。</p>

<!--more-->


<p>恶意代码只能提供一些基本信息，比如 app 和一般系统信息。</p>

<h3>从 Apps Store 下载 app 是否安全？</h3>

<p>我们已将由该盗版软件开发的 apps 从 App Store 中撤下，并拦截了通过该恶意软件开发的新 app 进入 App Store。</p>

<p>我们正与开发者紧密协作，以确保受到影响的 app 尽快回到 App Store 供用户使用。</p>

<p>我们将在支持页面上列出受此影响的前 25 个 apps，方便用户验证他们是否已将这些 app 更新到了最新版本。</p>

<p>用户还将会收到更多信息，以便了解他们下载的某 app 是否会存在问题。一旦开发者更新了他们的 app，用户可以通过在设备上运行更新解决存在的问题。</p>

<p>我们正努力让中国的开发者可以用更快的速度下载 Xcode 测试版本。开发者也可以通过 developer.apple.com 列出的步骤来验证他们的 Xcode 是否被篡改过。</p>

<h2>XcodeGhost Q&amp;A</h2>

<p><strong>I’ve heard about malicious apps created by XcodeGhost — what does this mean?</strong></p>

<p>We always recommend developers using the free, secure tools we provide them — including Xcode — to ensure they’re creating the most secure apps for App Store customers. Some developers downloaded counterfeit versions of Xcode that have been infected with malware and created apps that were just as infected.</p>

<p>Apple incorporates technologies like Gatekeeper expressly to prevent non-App Store and/or unsigned versions of programs, including Xcode, from being installed. Those protections had to have been deliberately disabled by the developer for something like XcodeGhost to successfully install.</p>

<p>As part of providing developers the industry&rsquo;s most advanced tools, Apple provides developers the following checks to ensure software is untampered:</p>

<pre><code>The Xcode app is code-signed by Apple.
When you download Xcode from the Mac App Store the code signature for Xcode is automatically checked and validated by your system.
When you download Xcode from the Apple Developer Program web site, the code signature for Xcode is automatically checked and validated by your system by default as long as Gatekeeper is not disabled.
</code></pre>

<h3>Why would a developer put customers at risk by downloading counterfeit software?</h3>

<p>Sometimes developers search for our tools on other, non-Apple sites in an effort to find faster downloads of developer tools.</p>

<h3>How does this affect me? How do I know if my device has been compromised?</h3>

<p>We have no information to suggest that the malware has been used to do anything malicious or that this exploit would have delivered any personally identifiable information had it been used.</p>

<p>We’re not aware of personally identifiable customer data being impacted and the code also did not have the ability to request customer credentials to gain iCloud and other service passwords.</p>

<p>As soon as we recognized these apps were using potentially malicious code we took them down. Developers are quickly updating their apps for users.</p>

<p>Malicious code could only have been able to deliver some general information such as the apps and general system information.</p>

<h3>Is it safe for me to download apps from App Store?</h3>

<p>We have removed the apps from the App Store that we know have been created with this counterfeit software and are blocking submissions of new apps that contain this malware from entering the App Store.</p>

<p>We’re working closely with developers to get impacted apps back on the App Store as quickly as possible for customers to enjoy.</p>

<p>A list of the top 25 most popular apps impacted will be listed soon so users can easily verify if they have downloaded the latest versions of these apps. After the top 25 impacted apps, the number of impacted users drops significantly.</p>

<p>Customers will be receiving more information letting them know if they’ve downloaded an app/apps that could have been compromised. Once a developer updates their app, that will fix the issue on the user’s device once they apply that update.</p>

<p>We’re working to make it faster for developers in China to download Xcode betas. To verify that their version of Xcode has not been altered, they can take the following steps posted at &lt;developer.apple.com>.</p>

<p>文章来自：<a href="http://www.apple.com/cn/xcodeghost/">http://www.apple.com/cn/xcodeghost/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AVFoundation和 GPUImage初探]]></title>
    <link href="http://www.superqq.com/blog/2015/08/24/avfoundation-gpuimage-find/"/>
    <updated>2015-08-24T11:21:01+08:00</updated>
    <id>http://www.superqq.com/blog/2015/08/24/avfoundation-gpuimage-find</id>
    <content type="html"><![CDATA[<p>文章来自：<a href="http://vonglo.me/2014/08/24/AVFoundation%E5%92%8C-GPUImage%E5%88%9D%E6%8E%A2/" target="_blank" title=“AVFoundation和 GPUImage初探”>AVFoundation和 GPUImage初探</a></p>

<p>最近在做视频相关的东西，然后熟悉了一下AVFoundation框架，以及强大的开源库GPUImage。在这里记录这个过程中遇到的一些问题，以及解决的方法。</p>

<h3>AVFoundation的一些基本概念</h3>

<p>根据苹果的官方文档，AVFoundation是用来播放和创建实时的视听媒体数据的框架，同时提供Objective-C接口来操作这些视听数据，比如编辑，旋转，重编码。本文着重讲的是视频的录制和编辑和GPUImage的一些简单使用，其他的都是一笔带过。来看下苹果文档的一个框架图。</p>

<p><img src="http://images.90159.com/08/frameworksBlockDiagram_2x.png" alt="1" /></p>

<h4>相关类</h4>

<ul>
<li><code>AVAsset</code></li>
<li><code>AVAssetTrack</code></li>
<li><code>AVComposition</code></li>
<li><code>AVVideoComposition</code></li>
<li><code>AVAudioMix</code></li>
<li><code>AVMutableAudioMixInputParameter</code></li>
<li><code>AVMutableVideoCompositionInstrution</code></li>
<li><code>AVMutableVideoCompositionLayerInstrution</code></li>
</ul>


<p>简单的播放可以使用MPMoviePlayerController或者MPMovieViewController就行,简单的录
制可以直接使用UIImagePickerController。同样简单的声音播放直接使用AVAudioPlayer，简单的录制直接使用AVAduioRecorder。如果你想要有更多的操作，可使用各种复杂的方式来控制播放，比如在同一时刻为同一个asset的不同片段使用不同的分辨率渲染，playitem来管理asset的呈现状态和方式,playitemtrack管理asset中的轨道（track）状态。</p>

<!--more-->


<p>在AVFoudation框架中最核心的类就是AVAsset，他是由一系列的媒体数据组成的，包括但不限于:时间、大小(size)、标题、字幕等。其中每一个单独的媒体数据称为轨道(track)。同样剪辑操作中，AVMutableComposition是一个核心类。</p>

<p><img src="http://images.90159.com/08/asset-track.png" alt="4" /></p>

<p>这里又一个重要的东西就是CMTime,它是一个结构体，定义如下:</p>

<p>typedef struct
{
    CMTimeValue    value;      <br/>
    CMTimeScale    timescale;  <br/>
    CMTimeFlags    flags;      <br/>
    CMTimeEpoch    epoch;      <br/>
} CMTime;
通常时间是等于value/timescale的，所以两个有相同时间的CMTime它们的timescale并不一定相同。关于更多CMTime的内容可以看<a href="https://developer.apple.com/library/ios/documentation/CoreMedia/Reference/CMTime/Reference/reference.html#//apple_ref/doc/uid/TP40009748">这里</a>。</p>

<h3>进阶</h3>

<h4>视频的录制</h4>

<p>这里用的是系统原生录制,关于录制通常用到的几个类就是AVCaptureDevice、
AVCaptureSession、AVCaptureDeviceInput、AVCaptureOutput,同样，来看一张图。</p>

<p><img src="http://images.90159.com/08/capture.png" alt="2" /></p>

<p>一般来说，如果你想修改视频的相关信息，如拍摄地点等，可以拿到output的metadata来修改。大致代码如下:</p>

<pre><code>NSMutableArray *array = [output.metadta mutableCopy];
AVMutableMetadataItem *item = [[AVMutableMetadataItem alloc] init];
item.keyspace = ...;
item.key = ...;
item.value = ...;
[array addObject:item];
output.metadata = array;
</code></pre>

<p>如果录制时候想要得到指定的视频size必须先指定分辨率，像这样</p>

<pre><code>if ([session canSetSessionPreset:AVCaptureSessionPreset640x480]){ 

    session.sessionPreset = AVCaptureSessionPreset640x480;
}
else {
    //设置失败
}
</code></pre>

<p>切换摄像头或其他输入源必须在beginConfiguration和commitConfiguration之间来处理，大致是这样</p>

<pre><code>[session beginConfiguration];
//移除某个输入源
//再添加某个输入源
//再为新添加的输入源进行必要的相关设置
//...其他操作
[session commitConfiguration];
</code></pre>

<p>如果想对实时视频帧进行相关的渲染操作,通过 setSampleBufferDelegate:queue:方法来为output设置代理，同时必须指定queue，代理方法将会在这些queue上面被调用。可以在自己的类里面实现AVCaptureVideoDataOutput的协议方法,通过实现
captureOutput:didOutputSampleBuffer:fromConnection:来拿到视频的每一帧，默认情况下这些视频帧会被用最有效的格式来输出到output,当然也可以在拍摄之前就为output进行相关设置。</p>

<pre><code>AVCaptureVideoDataOutput *videoDataOutput = [AVCaptureVideoDataOutput new];
NSDictionary *newSettings =@{ (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) };
videoDataOutput.videoSettings = newSettings;
</code></pre>

<p>说了这么多，感觉很虚，还是直接上代码，将以上部分衔接起来</p>

<pre><code>//自定义方法，小演示只添加了视频，没有添加声音，添加声音类似
- (void)yourCustomMethodName{
    AVCaptureSession *session = [[AVCaptureSession alloc] init];
    if ([session canSetSessionPreset:AVCaptureSessionPreset640x480]){ 

            session.sessionPreset = AVCaptureSessionPreset640x480;
        }
        else {
            //设置失败
        }
    AVCaptureDevice *device =
            [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];

    NSError *error = nil;
    AVCaptureDeviceInput *input =
            [AVCaptureDeviceInput deviceInputWithDevice:device error:&amp;error];
    if (!input) {
        // Handle the error appropriately.
    }
    if(session canAddInput:input){
        [session addInput:input];
    }
    AVCaptureVideoDataOutput *output = [[AVCaptureVideoDataOutput alloc] init];
    if(session canAddOutput:output){
        [session addOutput:output];
    }
    output.videoSettings =@{ (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) };
    //设置帧率(FPS),每秒15帧
    output.minFrameDuration = CMTimeMake(1, 15);
    dispatch_queue_t queue = dispatch_queue_create("CustomQueue", NULL);
    [output setSampleBufferDelegate:self queue:queue];
    dispatch_release(queue)
    NSString *mediaType = AVMediaTypeVideo;

 //用来显示录制的实时画面
    AVCaptureVideoPreviewLayer *captureVideoPreviewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:session];
    [self.view.layer addSublayer:captureVideoPreviewLayer];

    //用户是否允许启用摄像头
    [AVCaptureDevice requestAccessForMediaType:mediaType completionHandler:^(BOOL granted) {
        if (granted)
        {
            //Granted access to mediaType
            [self setDeviceAuthorized:YES];
            [session startRunning];
        }
        else
        {
            //Not granted access to mediaType
            dispatch_async(dispatch_get_main_queue(), ^{
            [[[UIAlertView alloc] initWithTitle:@"AVCam!"
                                        message:@"AVCam doesn't have permission to use Camera, please change privacy settings"
                                       delegate:self
                              cancelButtonTitle:@"OK"
                              otherButtonTitles:nil] show];
                    [self setDeviceAuthorized:NO];
            });
        }
    }];
}

//协议方法,获取每一帧，将每一帧转换成图片，你也可以进行其他的渲染操作
- (void)captureOutput:(AVCaptureOutput *)captureOutput
         didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
         fromConnection:(AVCaptureConnection *)connection {

    UIImage *image = imageFromSampleBuffer(sampleBuffer);
}
</code></pre>

<p>上面演示了如何取得每一帧实时画面,如果想要直接存成视频可使用AVCaptureMovieFileOutput,如下</p>

<pre><code>AVCaptureMovieFileOutput *movieFileOutput = [[AVCaptureMovieFileOutput alloc] init];
NSURL *fileURL = ...;    //存放位置
//指定代理
[aMovieFileOutput startRecordingToOutputFileURL:fileURL recordingDelegate:delete];
//也可以为其指定outputSettings
同样代理必须实现协议方法captureOutput:didFinishRecordingToOutputFileAtURL:fromConnections:error:,
</code></pre>

<p>当然还有其他各种具体的设置，如对焦、曝光、闪光灯以及白平衡等等均可以通过KVO来设置，每次设置前都加一个判断，是否支持指定模式,在这里不做详细叙述了,这里你可以看到<a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/04_MediaCapture.html#//apple_ref/doc/uid/TP40010188-CH5-SW14">更多</a>。</p>

<h4>视频的剪辑</h4>

<p>视频的剪辑包括但不限于:裁剪、旋转(改变transform)、添加水印、添加字幕、合并等。关于剪辑，无非就是取出视频中的轨道(视频和音频),然后对轨道进行一系列的操作变可以得到各种想要的效果。首先我们先来看下面一张图</p>

<p><img src="http://images.90159.com/08/composition.png" alt="3" /></p>

<p>AVMutableComposition是整个视频剪辑过程中的一个核心，下面着重讲解这个类。AVMutableComposition和AVAsset一样含有多个视/音频轨道，但是更重要的是，它可以将多个AVAssetTrack合并到一起，比如在视频合并时，可以直接将多段视频拼接到一个轨道(AVMutableCompositonTrcak)，音频也一样。通过借助AVMutableVideoComposition和AVMutableAudioMix来设置每一段的视/音频的属性，从而达到想要的视听效果，比如视频切换处的淡入淡出，声音的渐变，字幕等等。
关于上图的解释:首先通过将asset里面的轨道加载到composition的各轨道，然后通过audioMix和videoComposition对某个轨道进行对应操作,设置其相关属性。其中要用到的具体方法可以参见<a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html#//apple_ref/doc/uid/TP40010188-CH8-SW1">这里</a>。</p>

<p>其中图中1，2，3用到的方法为</p>

<pre><code>[1]
[mutableComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid]
[2]
[AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:mutableCompositionAudioTrack];`
[3]
[AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:mutableCompositionVideoTrack]
</code></pre>

<p>关于视频的剪辑的代码可以参见苹果给出的官方<a href="https://developer.apple.com/library/ios/samplecode/AVSimpleEditoriOS/Introduction/Intro.html#//apple_ref/doc/uid/DTS40012797">Demo</a>以及Raywendrich上的两篇文章<a href="http://www.raywenderlich.com/13418/how-to-play-record-edit-videos-in-ios">1</a>,<a href="http://www.raywenderlich.com/30200/avfoundation-tutorial-adding-overlays-and-animations-to-videos">2</a>。</p>

<h3>GPUImage</h3>

<p>什么?!你没听说过GPUImage?!那你赶紧去看看它的<a href="https://github.com/BradLarson/GPUImage/blob/master/README.md#overview">相关介绍</a>。GPUImage是一个基于OpenGL ES的一个强大的图像/视频处理库,封装好了各种滤镜同时也可以编写自定义的滤镜。至于他到底是如何强大,用了就知道。在这篇文章不是为了介绍它，而是列出一些我在使用过程中遇到的问题和解决方法。</p>

<h4>分段录制</h4>

<p>在使用GPUImageVideoCamera来录制的时候,可能需要分段录制,在GPUImage给出的视频录制Demo中直接只是录制一次，然而有时候需求可能是要录制多次，如果此时按照Demo的方法每次录制都要创建一个movieWriter,这样子的话每次都会在重新创建movieWriter并将它设置为videoCamera的audioEncodingTarget时候，界面都会卡顿一下，这是什么原因呢？因为videoCamera默认是不录制声音的，而每次创建movieWriter的时候都用到了movieWriter.hasAudioTrack = YES;,吊用这个之后videoCamera会自动去添加声音输入源,准备一些数据，所以这个过程会导致界面卡顿一下？这该怎么办呢？如果你有进到videoCamera的头文件去看的话你会发现这么一个方法和它的注释</p>

<pre><code>//Add audio capture to the session. Adding inputs and outputs freezes 
//the capture session momentarily, so you can use this method to add 
//the audio inputs and outputs early, if you’re going to set the 
//audioEncodingTarget later. Returns YES is the audio inputs and 
//outputs were added, or NO if they had already been added.

-(BOOL)addAudioInputsAndOutputs;
</code></pre>

<p>注释的大意是:录制的时候添加声音,添加输入源和输出源会暂时会使录制暂时卡住,所以在要使用声音的情况下要先调用该方法来防止录制被卡住。这不刚好就解决了上面的这个问题吗？所以问题就迎刃而解了,因为没看到这个,走了不少弯路,浪费了好长时间。</p>

<p>关于分段录制,可能有这么一个需求就是所有片段都是存于一个文件中而不是录制完成后将各段合并到一个视频文件中。这两个东西或许会帮到你<a href="http://blog.csdn.net/whf727/article/details/18702643">分段录制的实现</a>,<a href="https://github.com/leanlyne/GPUImageExtend">GPUImageExtend</a>。前者是基于系统的分段录制的实现,后者是GPUImageMoiveWriter的一个子类。</p>

<h4>所见即所得</h4>

<p>在录制的时候,使用GPUImageView来显示,因为给GPUImageView设置的大小是320*320的,如果不设置它的填充模式(fillMode)它是默认使用kGPUImageFillModePreserveAspectRatio即保持长宽比,其余空白处使用背景色填充,如果要设置成方形就得使用kGPUImageFillModePreserveAspectRatioAndFill,但是这个时候问题又来了假设你是用的录制分辨率是960x540,显示的画面则只会显示中间的540x540的画面,这个时候如果movieWriter的size设置为540x540,则最后保存的视频是失真的因为960被压到了540，整个画面变扁了。这个时候有两种解决方案</p>

<ul>
<li>1.使用GPUImageCropFilter,通过设置其cropRegion来裁出中间540x540部分。关于cropRegion要注意它是一个CGRect,它对坐标系做了一个归一化处理,所以让所有的取值都在0.0~1.0范围内,比如960x540裁剪至中间540x540部分则cropRegion为(0,((960-540)/2)/960,1,540/960)</li>
<li>2.改变videoComposition的perferTransfom使其只显示中间的540x540。
这样就完成了所见即所得。</li>
</ul>


<p>关于GPUImage的实时滤镜添加或给已存在的视频添加滤镜,Demo都给出了详细过程,依葫芦画瓢即可。有一点要注意的是,在一些操作完成的时候注意removeTarget,还有就是在使用movieFile来播放已存在视频并添加滤镜的时候是没有声音的,这是这个库的一个缺陷,Github上有人提了这个<a href="https://github.com/BradLarson/GPUImage/issues/458">issue</a>和<a href="https://gist.github.com/pgodino/3819907">一些解决办法</a>。同时在用movieFile处理视频的时候在切换滤镜的时候最好先cancelProcessing不然会有黑屏或卡顿现象出现。同样如果你是用老版本的GPUImage的时候,可能会遇到第一帧是红色的现象,有人提出这个issue后,作者修复了这个bug,切换到最新版的时候就不会有这种情况发生。发生这种情况的原因是视频掉帧,导致音频和视频不同步。</p>

<h3>总结</h3>

<p>AVFoundation还是有很多东西去做深层次的挖掘,GPUImage也是一样,有了这个强大的库,解决一些事情节省了大量时间。这次仅仅是一个小小的尝试,对于很多东西都是浅尝则止,文中难免会有错误,欢迎在评论中指正。如果你在使用GPUImage和AVFoundation有什么好的心得或者对一些问题有相应的解决方案,不妨在评论中分享一下。</p>

<hr />

<p>版权声明：我已将本文在微信公众平台的发表权「独家代理」给 iOS开发（ iOSDevTip ） 微信公众号。扫下方二维码即可关注「iOS 开发」：</p>

<p><img src="http://images.90159.com/icon/iOSDevTip.jpg" alt="iOSDevTip" /></p>
]]></content>
  </entry>
  
</feed>

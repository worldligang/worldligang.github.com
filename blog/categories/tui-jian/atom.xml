<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 推荐 | 刚刚在线]]></title>
  <link href="http://www.superqq.com/blog/categories/tui-jian/atom.xml" rel="self"/>
  <link href="http://www.superqq.com/"/>
  <updated>2015-11-16T09:39:15+08:00</updated>
  <id>http://www.superqq.com/</id>
  <author>
    <name><![CDATA[李刚]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[给你的iOS APP名称找到合适的长度&关键词]]></title>
    <link href="http://www.superqq.com/blog/2015/11/16/find-ios-app-key-words/"/>
    <updated>2015-11-16T09:37:20+08:00</updated>
    <id>http://www.superqq.com/blog/2015/11/16/find-ios-app-key-words</id>
    <content type="html"><![CDATA[<p>今天这篇是关于iOS APP的名称长度，顺便简要说说关键词。一谈到应用程序上线就避免不了App Store Optimization (ASO)，APP的名称又是一个不可不谈的话题。</p>

<h2>一、APP名称的选择</h2>

<h3>1、仅包含应用的名称</h3>

<p>一般建议使用这个，因为看起来美观一点，在应用标题的里面没有包含关键词的话，有时候看起来好像很牛逼一样，因为好像不需要ASO了，不需要去堆关键词，但是这个好像对大多数来说不适用。</p>

<h3>2、名称中添加很多关键词</h3>

<p>将很多相关关键词添加到名称来争取ASO的优势，但是粗略看起来好像是不专业的，尽管这样看起来不是很美观，但是有用，所以即便是一些逼格相当高的应用依然会加关键词进去，长度和关键词的重复次数就看运营人员的心情了。</p>

<p>那么一种是干净美观，一种是包含众多关键词的名称，我们总要给他找个平衡点。这篇文章将告诉你如何为你的iOS APP找出理想的名称长度，跟之前那篇Google Play 描述的关键词密度类似。</p>

<h2>二、两种类型的名称</h2>

<p>其实每个APP都有两个名称，一个主，一个副，合起来就是一个title，你打开一个网页，在浏览器标签上看到的这个标题就是这个网页的title，一般是网站名字+文章名字，大多数是文章名在前，网站名在后。但都是有字符限制的，在iOS APP里面，iTunes Connect里，你要填进去，苹果也会给个255来限制，因为过长也没意思，所以我就在255以内寻找一个合适的点。</p>

<p>我们需要ASO的是现实在iTunes里面的那个，其实相当于总共有2个，开发者一般比较熟悉iTunes Connect，因为经常需要填写那些字段上线APP。不熟悉的自己登录进去看看，想看的自己没有APP的，那就先收藏这篇文章，备用到时候参考。</p>

<h2>三、如何找到理想的名称长度</h2>

<p>关于最理想的长度，并不是一个固定的标准，因为对于每个APP来说要展现的关键词是不一样的，即便都通过语言描述展示一个词，也会有不一样的，比如 “查违章”，“违章查询”这两个词对一个做违章查询的APP与 “天气预报”“查天气”对应一个做天气预报的APP，都是不一样的，我不能说150个字符是最好的，因为这样说的话就是傻逼了。</p>

<p>其实顺便说一下，有些开发者不知道开发什么，跟着去做一堆烂游戏，还不如去找几个这种普普通通大众的功能性APP需求好好做一个。我经常遇到开发者问做什么APP赚钱？现在做APP还能赚到钱么？做APP怎么赚钱？</p>

<p>这种类型的问题，我这里统一作答，做APP是赚钱的，也是不赚钱的，关键看你选什么做，怎么做，做出来的APP怎么样？如果想在AppStore里面混到钱，可以多看看别人，坚持每天下载几款APP，慢慢研究，不要急，不要觉得好像自己现在不做都被别人做了，这种想法也许不一定成熟。认真的准备，勤快的实践。下面是确定名称的时候，可以考虑到的一些因素：</p>

<h3>1、保持短一点</h3>

<p>由于较短一点的名称看起来更品牌性，包含5个以内的关键词，最好3个就行啦，三个不一样的</p>

<p>但是这也不是一个绝对的规则，比如你觉得几个关键词都比较类似，可以都加进去，不必要的就不用加了，不一定每个APP都要加上QQ，微信这种关键词进去。</p>

<h3>2、注意关键词的竞争</h3>

<p>像做网页，我们搜汽车，新做一个网站是很难排上去的，因为大家都知道这类的网站已经比较成熟，已经在搜索引擎的算法上攻坚多年，已经坚挺的占领了前面的位置。在淘宝里面，商品排名，搜T恤，销量很大的已经排在前面，新宝贝排上去，短时间很困难，除非你自己有一些特殊的资源。在应用商店里面也有一些类似的算法，别人已经坚挺，我们就不一定首先从最难的词去优化，你可以通过一些工具和查询来看看竞争度，这个不能一味依靠一个工具，有些是动态的。</p>

<p>之所以是动态的，这里传达给一些投机取巧的人，一些热点的东西，有些人也喜欢到AppStore里面去搜。</p>

<h3>3、看起来有意思一点</h3>

<p>这个和名称的长度是没有关系的因素，但是你在优化名称的时候，可以参考，比如你要全部的标题里面的词语最终组成一个完整的句子作为一个标题，那为什么不给自己减轻难度把截断之前的弄的舒服一点呢（手机上显示的部分）。</p>

<p>我们不能太侥幸的去和某些APP比，比如堆词语，我看到有些运营高手是这样做的，把整个当成ABC，A是主名，B是一句有吸引力的话并包含关键词，C就是一些关键词的组合了。有个东西叫组合，真的有个东西叫组合，你懂什么叫分词和组合么？不要看到别人当前的下载量评分量来判断你用此方法就可以胜出。</p>

<blockquote><p>来自：<a href="http://www.appying.com/app-store-tuiguang/aso/fdsgs/">http://www.appying.com/app-store-tuiguang/aso/fdsgs/</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为自己的应用配备上 3D Touch 功能]]></title>
    <link href="http://www.superqq.com/blog/2015/10/31/app-touch-3d-function/"/>
    <updated>2015-10-31T10:35:24+08:00</updated>
    <id>http://www.superqq.com/blog/2015/10/31/app-touch-3d-function</id>
    <content type="html"><![CDATA[<p>随着 iPhone 6s 以及 iPhone 6s Plus 的发布，开发者们现在就可以为自己的应用配备上 3D Touch 功能了，从而给界面交互方式开启一个新的维度。</p>

<p>正如苹果所言，开发者可以通过非常简单的 API 来使用 3D Touch ，从根本上来说，也就是 UITouch 的一个简单的新属性。</p>

<pre><code>override func touchesBegan(touches: Set&lt;UITouch&gt;, withEvent event: UIEvent?) {
     guard let touch = touches.first else { return }
     if traitCollection.forceTouchCapability == .Available {
        println("Touch pressure is \(touch.force), maximum possible force is \(touch.maximumPossibleForce)")
     }
}
</code></pre>

<p>这个新的 API 可以让应用发挥出巨大的潜力，比如说游戏中的额外控制选项、绘图应用中的细粒度(fine-grained)控制，甚至是用来替代我们在 iOS 设备中使用过的长按操作(tap-and-hold)的极佳选择。</p>

<p>除了 UITouch 中新增的 API 外，苹果还为应用提供了两个用来增加3D Touch 功能的类集：UIPreviewAction 和 UIApplicationShortcutItem。</p>

<p>UIPreviewAction允许开发者在用户使用 3D Touch 功能触控一个 UI 元素的时候，快速地在一个新的预览窗口中显示某些内容。这种快速浏览应用特定内容的方式真的非常棒，比如说我们可以快速预览邮件信息、照片，甚至是网页内容，而无需弹出一个完整的视图控制器。</p>

<p>UIApplicationShortcutItem对象能够让 iOS 主屏幕激活一项令人惊叹的新特性。当用户使用 3D Touch 按下某个应用的图标时，一个选项列表就会被弹出，允许用户快速跳转至应用的特定部分，或者执行某项应用内的功能。</p>

<p><img src="http://images.90159.com/10/touch.jpg" alt="touch" /></p>

<p>总而言之，3D Touch 的引入给 iOS 设备解锁了一个全新的交互方式，并且将会给接下来的 iOS 应用带来新一代的创新。关于3D Touch 的实例代码和相关信息可以在苹果开发者网站的3D Touch网页上找到，祝你好运！</p>

<p>作者：Tim Oliver
@TimOliverAU — iComics创始人</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[五个案例让你明白GCD死锁]]></title>
    <link href="http://www.superqq.com/blog/2015/10/16/five-case-know-gcd/"/>
    <updated>2015-10-16T20:29:42+08:00</updated>
    <id>http://www.superqq.com/blog/2015/10/16/five-case-know-gcd</id>
    <content type="html"><![CDATA[<pre><code>作者：brighttj（@saitjr

网址：http://www.brighttj.com/ios/ios-gcd-deadlock.html
</code></pre>

<p>死锁一直都是在使用多线程时，需要注意的一个问题。以前对同步、异步，串行、并行只有一个模糊的概念，想想也是时候整理一下了。再看看之前的博客，已经很久没有干货了【说得好像之前有干货一样】，所以，这篇博客，我尽最大努力，也借鉴了很多其他博客中的例子，来讲解GCD死锁问题。</p>

<p>环境信息：</p>

<p>Mac OS X 10.10.5</p>

<p>Xcode 6.4</p>

<p>iOS  8.4</p>

<h2>串行与并行</h2>

<p>在使用GCD的时候，我们会把需要处理的任务放到Block中，然后将任务追加到相应的队列里面，这个队列，叫做Dispatch Queue。然而，存在于两种Dispatch Queue，一种是要等待上一个执行完，再执行下一个的Serial Dispatch Queue，这叫做串行队列；另一种，则是不需要上一个执行完，就能执行下一个的Concurrent Dispatch Queue，叫做并行队列。这两种，均遵循FIFO原则。</p>

<pre><code>举一个简单的例子，在三个任务中输出1、2、3，串行队列输出是有序的1、2、3，但是并行队列的先后顺序就不一定了。
</code></pre>

<p>那么，并行队列又是怎么在执行呢？</p>

<p>虽然可以同时多个任务的处理，但是并行队列的处理量，还是要根据当前系统状态来。如果当前系统状态最多处理2个任务，那么1、2会排在前面，3什么时候操作，就看1或者2谁先完成，然后3接在后面。</p>

<p>串行和并行就简单说到这里，关于它们的技术点其实还有很多，可以自行了解。</p>

<h2>同步与异步</h2>

<p>串行与并行针对的是队列，而同步与异步，针对的则是线程。最大的区别在于，同步线程要阻塞当前线程，必须要等待同步线程中的任务执行完，返回以后，才能继续执行下一任务；而异步线程则是不用等待。</p>

<p>仅凭这几句话还是很难理解，所以之后准备了很多案例，可以边分析边理解。</p>

<!--more-->


<h2>GCD API</h2>

<p>GCD API很多，这里仅介绍本文用到的。</p>

<ol>
<li><p>系统标准提供的两个队列</p>

<pre><code> // 全局队列，也是一个并行队列

 dispatch_get_global_queue 

 // 主队列，在主线程中运行，因为主线程只有一个，所以这是一个串行队列

 dispatch_get_main_queue 
</code></pre></li>
<li><p>除此之外，还可以自己生成队列</p>

<pre><code> // 从DISPATCH_QUEUE_SERIAL看出，这是串行队列

 dispatch_queue_create("com.demo.serialQueue", DISPATCH_QUEUE_SERIAL) 

 // 同理，这是一个并行队列

 dispatch_queue_create("com.demo.concurrentQueue", DISPATCH_QUEUE_CONCURRENT) 
</code></pre></li>
</ol>


<p>接下来是同步与异步线程的创建：</p>

<pre><code>dispatch_sync(..., ^(block)) // 同步线程

dispatch_async(..., ^(block)) // 异步线程
</code></pre>

<h2>案例与分析</h2>

<p>假设你已经基本了解了上面提到的知识，接下来进入案例讲解阶段。</p>

<h2>案例一：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_sync(dispatch_get_main_queue(), ^{

    NSLog(@"2"); // 任务2

});

NSLog(@"3"); // 任务3
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1
</code></pre>

<p>分析：</p>

<pre><code>dispatch_sync表示是一个同步线程；

dispatch_get_main_queue表示运行在主线程中的主队列；

任务2是同步线程的任务。
</code></pre>

<p>首先执行任务1，这是肯定没问题的，只是接下来，程序遇到了同步线程，那么它会进入等待，等待任务2执行完，然后执行任务3。但这是队列，有任务来，当然会将任务加到队尾，然后遵循FIFO原则执行任务。那么，现在任务2就会被加到最后，任务3排在了任务2前面，问题来了：</p>

<pre><code>任务3要等任务2执行完才能执行，任务2由排在任务3后面，意味着任务2要在任务3执行完才能执行，所以他们进入了互相等待的局面。【既然这样，那干脆就卡在这里吧】这就是死锁。
</code></pre>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-1.png" alt="deadlock" /></p>

<h2>案例二：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_sync(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0), ^{

    NSLog(@"2"); // 任务2

});

NSLog(@"3"); // 任务3
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

2

3
</code></pre>

<p>分析：</p>

<p>首先执行任务1，接下来会遇到一个同步线程，程序会进入等待。等待任务2执行完成以后，才能继续执行任务3。从dispatch_get_global_queue可以看出，任务2被加入到了全局的并行队列中，当并行队列执行完任务2以后，返回到主队列，继续执行任务3。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-2.png" alt="2" /></p>

<h2>案例三：</h2>

<pre><code>dispatch_queue_t queue = dispatch_queue_create("com.demo.serialQueue", DISPATCH_QUEUE_SERIAL);

NSLog(@"1"); // 任务1

dispatch_async(queue, ^{

    NSLog(@"2"); // 任务2

    dispatch_sync(queue, ^{  

        NSLog(@"3"); // 任务3

    });

    NSLog(@"4"); // 任务4

});

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

5

2

// 5和2的顺序不一定
</code></pre>

<p>分析：</p>

<p>这个案例没有使用系统提供的串行或并行队列，而是自己通过dispatch_queue_create函数创建了一个DISPATCH_QUEUE_SERIAL的串行队列。</p>

<pre><code>执行任务1；

遇到异步线程，将【任务2、同步线程、任务4】加入串行队列中。因为是异步线程，所以在主线程中的任务5不必等待异步线程中的所有任务完成；

因为任务5不必等待，所以2和5的输出顺序不能确定；

任务2执行完以后，遇到同步线程，这时，将任务3加入串行队列；

又因为任务4比任务3早加入串行队列，所以，任务3要等待任务4完成以后，才能执行。但是任务3所在的同步线程会阻塞，所以任务4必须等任务3执行完以后再执行。这就又陷入了无限的等待中，造成死锁。
</code></pre>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-3.png" alt="3" /></p>

<h2>案例四：</h2>

<pre><code>NSLog(@"1"); // 任务1

dispatch_async(dispatch_get_global_queue(0, 0), ^{

    NSLog(@"2"); // 任务2

    dispatch_sync(dispatch_get_main_queue(), ^{

        NSLog(@"3"); // 任务3

    });

    NSLog(@"4"); // 任务4

});

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

2

5

3

4

// 5和2的顺序不一定
</code></pre>

<p>分析：</p>

<p>首先，将【任务1、异步线程、任务5】加入Main Queue中，异步线程中的任务是：【任务2、同步线程、任务4】。</p>

<p>所以，先执行任务1，然后将异步线程中的任务加入到Global Queue中，因为异步线程，所以任务5不用等待，结果就是2和5的输出顺序不一定。</p>

<p>然后再看异步线程中的任务执行顺序。任务2执行完以后，遇到同步线程。将同步线程中的任务加入到Main Queue中，这时加入的任务3在任务5的后面。</p>

<p>当任务3执行完以后，没有了阻塞，程序继续执行任务4。</p>

<p>从以上的分析来看，得到的几个结果：1最先执行；2和5顺序不一定；4一定在3后面。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-4.png" alt="4" /></p>

<h2>案例五：</h2>

<pre><code>dispatch_async(dispatch_get_global_queue(0, 0), ^{

    NSLog(@"1"); // 任务1

    dispatch_sync(dispatch_get_main_queue(), ^{

        NSLog(@"2"); // 任务2

    });

    NSLog(@"3"); // 任务3

});

NSLog(@"4"); // 任务4

while (1) {

}

NSLog(@"5"); // 任务5
</code></pre>

<p>结果，控制台输出：</p>

<pre><code>1

4

// 1和4的顺序不一定
</code></pre>

<p>分析：</p>

<p>和上面几个案例的分析类似，先来看看都有哪些任务加入了Main Queue：【异步线程、任务4、死循环、任务5】。</p>

<p>在加入到Global Queue异步线程中的任务有：【任务1、同步线程、任务3】。</p>

<p>第一个就是异步线程，任务4不用等待，所以结果任务1和任务4顺序不一定。</p>

<p>任务4完成后，程序进入死循环，Main Queue阻塞。但是加入到Global Queue的异步线程不受影响，继续执行任务1后面的同步线程。</p>

<p>同步线程中，将任务2加入到了主线程，并且，任务3等待任务2完成以后才能执行。这时的主线程，已经被死循环阻塞了。所以任务2无法执行，当然任务3也无法执行，在死循环后的任务5也不会执行。</p>

<p>最终，只能得到1和4顺序不定的结果。</p>

<p><img src="http://www.brighttj.com/wp-content/uploads/2015/09/gcd-deadlock-5.png" alt="5" /></p>

<h2>参考</h2>

<pre><code>http://www.jianshu.com/p/0b0d9b1f1f19

http://www.cnblogs.com/tangbinblog/p/4133481.html
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关 XcodeGhost 的问题和解答]]></title>
    <link href="http://www.superqq.com/blog/2015/09/24/apple-xcodeghost-answer/"/>
    <updated>2015-09-24T00:09:03+08:00</updated>
    <id>http://www.superqq.com/blog/2015/09/24/apple-xcodeghost-answer</id>
    <content type="html"><![CDATA[<p><strong>我听说了由 XcodeGhost 开发的恶意 app — 这是怎么回事？</strong></p>

<p>我们一直建议开发者使用由我们提供的免费、安全的工具，包括 Xcode，从而确保他们为 App Store 的用户创造出安全的 app。一些开发者下载了已被恶意软件感染的盗版 Xcode，由此开发的 app 也同样受到感染。</p>

<p>Apple 特意使用诸如 Gatekeeper 等技术，以防止安装从非 App Store 渠道下载的应用程序，和 / 或安装包括 Xcode 在内的未签名的应用程序。当开发者为了能安装类似 XcodeGhost 等恶意程序时，这些保护措施会被刻意地禁用。</p>

<p>作为 Apple 向开发者提供的业界先进工具之一，以下措施可以确保软件未被篡改：</p>

<pre><code>Xcode app 有 Apple 的代码签名。
从 Mac App Store 下载 Xcode 时，开发者的电脑系统自动对 Xcode 的代码签名会进行检查和验证。
从 Apple Developer Program 网站下载 Xcode 时，只要 Gatekeeper 没有被禁用，默认开发者的电脑系统对 Xcode 代码签名自动进行检查和验证。
</code></pre>

<h3>为什么开发者会不顾用户的安全下载盗版软件？</h3>

<p>为了更快下载我们的开发者工具，开发者有时会从其他非 Apple 站点搜寻。</p>

<h3>这会对我有什么影响吗？如何得知我的设备是否受到了影响？</h3>

<p>我们目前没有任何信息表明这些恶意软件与任何恶意事件相关，也没有信息表明这些软件被使用在传播任何个人身份信息的用途上。</p>

<p>我们目前没有看到任何客户个人身份信息受到影响，而且代码无法通过用户身份请求来获取 iCloud 或其他服务的密码。</p>

<p>只要一经发现这些 app 有可能通过恶意代码开发，我们就对其进行下架处理。开发者们正在快速更新他们的 app，以便用户使用。</p>

<!--more-->


<p>恶意代码只能提供一些基本信息，比如 app 和一般系统信息。</p>

<h3>从 Apps Store 下载 app 是否安全？</h3>

<p>我们已将由该盗版软件开发的 apps 从 App Store 中撤下，并拦截了通过该恶意软件开发的新 app 进入 App Store。</p>

<p>我们正与开发者紧密协作，以确保受到影响的 app 尽快回到 App Store 供用户使用。</p>

<p>我们将在支持页面上列出受此影响的前 25 个 apps，方便用户验证他们是否已将这些 app 更新到了最新版本。</p>

<p>用户还将会收到更多信息，以便了解他们下载的某 app 是否会存在问题。一旦开发者更新了他们的 app，用户可以通过在设备上运行更新解决存在的问题。</p>

<p>我们正努力让中国的开发者可以用更快的速度下载 Xcode 测试版本。开发者也可以通过 developer.apple.com 列出的步骤来验证他们的 Xcode 是否被篡改过。</p>

<h2>XcodeGhost Q&amp;A</h2>

<p><strong>I’ve heard about malicious apps created by XcodeGhost — what does this mean?</strong></p>

<p>We always recommend developers using the free, secure tools we provide them — including Xcode — to ensure they’re creating the most secure apps for App Store customers. Some developers downloaded counterfeit versions of Xcode that have been infected with malware and created apps that were just as infected.</p>

<p>Apple incorporates technologies like Gatekeeper expressly to prevent non-App Store and/or unsigned versions of programs, including Xcode, from being installed. Those protections had to have been deliberately disabled by the developer for something like XcodeGhost to successfully install.</p>

<p>As part of providing developers the industry&rsquo;s most advanced tools, Apple provides developers the following checks to ensure software is untampered:</p>

<pre><code>The Xcode app is code-signed by Apple.
When you download Xcode from the Mac App Store the code signature for Xcode is automatically checked and validated by your system.
When you download Xcode from the Apple Developer Program web site, the code signature for Xcode is automatically checked and validated by your system by default as long as Gatekeeper is not disabled.
</code></pre>

<h3>Why would a developer put customers at risk by downloading counterfeit software?</h3>

<p>Sometimes developers search for our tools on other, non-Apple sites in an effort to find faster downloads of developer tools.</p>

<h3>How does this affect me? How do I know if my device has been compromised?</h3>

<p>We have no information to suggest that the malware has been used to do anything malicious or that this exploit would have delivered any personally identifiable information had it been used.</p>

<p>We’re not aware of personally identifiable customer data being impacted and the code also did not have the ability to request customer credentials to gain iCloud and other service passwords.</p>

<p>As soon as we recognized these apps were using potentially malicious code we took them down. Developers are quickly updating their apps for users.</p>

<p>Malicious code could only have been able to deliver some general information such as the apps and general system information.</p>

<h3>Is it safe for me to download apps from App Store?</h3>

<p>We have removed the apps from the App Store that we know have been created with this counterfeit software and are blocking submissions of new apps that contain this malware from entering the App Store.</p>

<p>We’re working closely with developers to get impacted apps back on the App Store as quickly as possible for customers to enjoy.</p>

<p>A list of the top 25 most popular apps impacted will be listed soon so users can easily verify if they have downloaded the latest versions of these apps. After the top 25 impacted apps, the number of impacted users drops significantly.</p>

<p>Customers will be receiving more information letting them know if they’ve downloaded an app/apps that could have been compromised. Once a developer updates their app, that will fix the issue on the user’s device once they apply that update.</p>

<p>We’re working to make it faster for developers in China to download Xcode betas. To verify that their version of Xcode has not been altered, they can take the following steps posted at &lt;developer.apple.com>.</p>

<p>文章来自：<a href="http://www.apple.com/cn/xcodeghost/">http://www.apple.com/cn/xcodeghost/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AVFoundation和 GPUImage初探]]></title>
    <link href="http://www.superqq.com/blog/2015/08/24/avfoundation-gpuimage-find/"/>
    <updated>2015-08-24T11:21:01+08:00</updated>
    <id>http://www.superqq.com/blog/2015/08/24/avfoundation-gpuimage-find</id>
    <content type="html"><![CDATA[<p>文章来自：<a href="http://vonglo.me/2014/08/24/AVFoundation%E5%92%8C-GPUImage%E5%88%9D%E6%8E%A2/" target="_blank" title=“AVFoundation和 GPUImage初探”>AVFoundation和 GPUImage初探</a></p>

<p>最近在做视频相关的东西，然后熟悉了一下AVFoundation框架，以及强大的开源库GPUImage。在这里记录这个过程中遇到的一些问题，以及解决的方法。</p>

<h3>AVFoundation的一些基本概念</h3>

<p>根据苹果的官方文档，AVFoundation是用来播放和创建实时的视听媒体数据的框架，同时提供Objective-C接口来操作这些视听数据，比如编辑，旋转，重编码。本文着重讲的是视频的录制和编辑和GPUImage的一些简单使用，其他的都是一笔带过。来看下苹果文档的一个框架图。</p>

<p><img src="http://images.90159.com/08/frameworksBlockDiagram_2x.png" alt="1" /></p>

<h4>相关类</h4>

<ul>
<li><code>AVAsset</code></li>
<li><code>AVAssetTrack</code></li>
<li><code>AVComposition</code></li>
<li><code>AVVideoComposition</code></li>
<li><code>AVAudioMix</code></li>
<li><code>AVMutableAudioMixInputParameter</code></li>
<li><code>AVMutableVideoCompositionInstrution</code></li>
<li><code>AVMutableVideoCompositionLayerInstrution</code></li>
</ul>


<p>简单的播放可以使用MPMoviePlayerController或者MPMovieViewController就行,简单的录
制可以直接使用UIImagePickerController。同样简单的声音播放直接使用AVAudioPlayer，简单的录制直接使用AVAduioRecorder。如果你想要有更多的操作，可使用各种复杂的方式来控制播放，比如在同一时刻为同一个asset的不同片段使用不同的分辨率渲染，playitem来管理asset的呈现状态和方式,playitemtrack管理asset中的轨道（track）状态。</p>

<!--more-->


<p>在AVFoudation框架中最核心的类就是AVAsset，他是由一系列的媒体数据组成的，包括但不限于:时间、大小(size)、标题、字幕等。其中每一个单独的媒体数据称为轨道(track)。同样剪辑操作中，AVMutableComposition是一个核心类。</p>

<p><img src="http://images.90159.com/08/asset-track.png" alt="4" /></p>

<p>这里又一个重要的东西就是CMTime,它是一个结构体，定义如下:</p>

<p>typedef struct
{
    CMTimeValue    value;      <br/>
    CMTimeScale    timescale;  <br/>
    CMTimeFlags    flags;      <br/>
    CMTimeEpoch    epoch;      <br/>
} CMTime;
通常时间是等于value/timescale的，所以两个有相同时间的CMTime它们的timescale并不一定相同。关于更多CMTime的内容可以看<a href="https://developer.apple.com/library/ios/documentation/CoreMedia/Reference/CMTime/Reference/reference.html#//apple_ref/doc/uid/TP40009748">这里</a>。</p>

<h3>进阶</h3>

<h4>视频的录制</h4>

<p>这里用的是系统原生录制,关于录制通常用到的几个类就是AVCaptureDevice、
AVCaptureSession、AVCaptureDeviceInput、AVCaptureOutput,同样，来看一张图。</p>

<p><img src="http://images.90159.com/08/capture.png" alt="2" /></p>

<p>一般来说，如果你想修改视频的相关信息，如拍摄地点等，可以拿到output的metadata来修改。大致代码如下:</p>

<pre><code>NSMutableArray *array = [output.metadta mutableCopy];
AVMutableMetadataItem *item = [[AVMutableMetadataItem alloc] init];
item.keyspace = ...;
item.key = ...;
item.value = ...;
[array addObject:item];
output.metadata = array;
</code></pre>

<p>如果录制时候想要得到指定的视频size必须先指定分辨率，像这样</p>

<pre><code>if ([session canSetSessionPreset:AVCaptureSessionPreset640x480]){ 

    session.sessionPreset = AVCaptureSessionPreset640x480;
}
else {
    //设置失败
}
</code></pre>

<p>切换摄像头或其他输入源必须在beginConfiguration和commitConfiguration之间来处理，大致是这样</p>

<pre><code>[session beginConfiguration];
//移除某个输入源
//再添加某个输入源
//再为新添加的输入源进行必要的相关设置
//...其他操作
[session commitConfiguration];
</code></pre>

<p>如果想对实时视频帧进行相关的渲染操作,通过 setSampleBufferDelegate:queue:方法来为output设置代理，同时必须指定queue，代理方法将会在这些queue上面被调用。可以在自己的类里面实现AVCaptureVideoDataOutput的协议方法,通过实现
captureOutput:didOutputSampleBuffer:fromConnection:来拿到视频的每一帧，默认情况下这些视频帧会被用最有效的格式来输出到output,当然也可以在拍摄之前就为output进行相关设置。</p>

<pre><code>AVCaptureVideoDataOutput *videoDataOutput = [AVCaptureVideoDataOutput new];
NSDictionary *newSettings =@{ (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) };
videoDataOutput.videoSettings = newSettings;
</code></pre>

<p>说了这么多，感觉很虚，还是直接上代码，将以上部分衔接起来</p>

<pre><code>//自定义方法，小演示只添加了视频，没有添加声音，添加声音类似
- (void)yourCustomMethodName{
    AVCaptureSession *session = [[AVCaptureSession alloc] init];
    if ([session canSetSessionPreset:AVCaptureSessionPreset640x480]){ 

            session.sessionPreset = AVCaptureSessionPreset640x480;
        }
        else {
            //设置失败
        }
    AVCaptureDevice *device =
            [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];

    NSError *error = nil;
    AVCaptureDeviceInput *input =
            [AVCaptureDeviceInput deviceInputWithDevice:device error:&amp;error];
    if (!input) {
        // Handle the error appropriately.
    }
    if(session canAddInput:input){
        [session addInput:input];
    }
    AVCaptureVideoDataOutput *output = [[AVCaptureVideoDataOutput alloc] init];
    if(session canAddOutput:output){
        [session addOutput:output];
    }
    output.videoSettings =@{ (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) };
    //设置帧率(FPS),每秒15帧
    output.minFrameDuration = CMTimeMake(1, 15);
    dispatch_queue_t queue = dispatch_queue_create("CustomQueue", NULL);
    [output setSampleBufferDelegate:self queue:queue];
    dispatch_release(queue)
    NSString *mediaType = AVMediaTypeVideo;

 //用来显示录制的实时画面
    AVCaptureVideoPreviewLayer *captureVideoPreviewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:session];
    [self.view.layer addSublayer:captureVideoPreviewLayer];

    //用户是否允许启用摄像头
    [AVCaptureDevice requestAccessForMediaType:mediaType completionHandler:^(BOOL granted) {
        if (granted)
        {
            //Granted access to mediaType
            [self setDeviceAuthorized:YES];
            [session startRunning];
        }
        else
        {
            //Not granted access to mediaType
            dispatch_async(dispatch_get_main_queue(), ^{
            [[[UIAlertView alloc] initWithTitle:@"AVCam!"
                                        message:@"AVCam doesn't have permission to use Camera, please change privacy settings"
                                       delegate:self
                              cancelButtonTitle:@"OK"
                              otherButtonTitles:nil] show];
                    [self setDeviceAuthorized:NO];
            });
        }
    }];
}

//协议方法,获取每一帧，将每一帧转换成图片，你也可以进行其他的渲染操作
- (void)captureOutput:(AVCaptureOutput *)captureOutput
         didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
         fromConnection:(AVCaptureConnection *)connection {

    UIImage *image = imageFromSampleBuffer(sampleBuffer);
}
</code></pre>

<p>上面演示了如何取得每一帧实时画面,如果想要直接存成视频可使用AVCaptureMovieFileOutput,如下</p>

<pre><code>AVCaptureMovieFileOutput *movieFileOutput = [[AVCaptureMovieFileOutput alloc] init];
NSURL *fileURL = ...;    //存放位置
//指定代理
[aMovieFileOutput startRecordingToOutputFileURL:fileURL recordingDelegate:delete];
//也可以为其指定outputSettings
同样代理必须实现协议方法captureOutput:didFinishRecordingToOutputFileAtURL:fromConnections:error:,
</code></pre>

<p>当然还有其他各种具体的设置，如对焦、曝光、闪光灯以及白平衡等等均可以通过KVO来设置，每次设置前都加一个判断，是否支持指定模式,在这里不做详细叙述了,这里你可以看到<a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/04_MediaCapture.html#//apple_ref/doc/uid/TP40010188-CH5-SW14">更多</a>。</p>

<h4>视频的剪辑</h4>

<p>视频的剪辑包括但不限于:裁剪、旋转(改变transform)、添加水印、添加字幕、合并等。关于剪辑，无非就是取出视频中的轨道(视频和音频),然后对轨道进行一系列的操作变可以得到各种想要的效果。首先我们先来看下面一张图</p>

<p><img src="http://images.90159.com/08/composition.png" alt="3" /></p>

<p>AVMutableComposition是整个视频剪辑过程中的一个核心，下面着重讲解这个类。AVMutableComposition和AVAsset一样含有多个视/音频轨道，但是更重要的是，它可以将多个AVAssetTrack合并到一起，比如在视频合并时，可以直接将多段视频拼接到一个轨道(AVMutableCompositonTrcak)，音频也一样。通过借助AVMutableVideoComposition和AVMutableAudioMix来设置每一段的视/音频的属性，从而达到想要的视听效果，比如视频切换处的淡入淡出，声音的渐变，字幕等等。
关于上图的解释:首先通过将asset里面的轨道加载到composition的各轨道，然后通过audioMix和videoComposition对某个轨道进行对应操作,设置其相关属性。其中要用到的具体方法可以参见<a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html#//apple_ref/doc/uid/TP40010188-CH8-SW1">这里</a>。</p>

<p>其中图中1，2，3用到的方法为</p>

<pre><code>[1]
[mutableComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid]
[2]
[AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:mutableCompositionAudioTrack];`
[3]
[AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:mutableCompositionVideoTrack]
</code></pre>

<p>关于视频的剪辑的代码可以参见苹果给出的官方<a href="https://developer.apple.com/library/ios/samplecode/AVSimpleEditoriOS/Introduction/Intro.html#//apple_ref/doc/uid/DTS40012797">Demo</a>以及Raywendrich上的两篇文章<a href="http://www.raywenderlich.com/13418/how-to-play-record-edit-videos-in-ios">1</a>,<a href="http://www.raywenderlich.com/30200/avfoundation-tutorial-adding-overlays-and-animations-to-videos">2</a>。</p>

<h3>GPUImage</h3>

<p>什么?!你没听说过GPUImage?!那你赶紧去看看它的<a href="https://github.com/BradLarson/GPUImage/blob/master/README.md#overview">相关介绍</a>。GPUImage是一个基于OpenGL ES的一个强大的图像/视频处理库,封装好了各种滤镜同时也可以编写自定义的滤镜。至于他到底是如何强大,用了就知道。在这篇文章不是为了介绍它，而是列出一些我在使用过程中遇到的问题和解决方法。</p>

<h4>分段录制</h4>

<p>在使用GPUImageVideoCamera来录制的时候,可能需要分段录制,在GPUImage给出的视频录制Demo中直接只是录制一次，然而有时候需求可能是要录制多次，如果此时按照Demo的方法每次录制都要创建一个movieWriter,这样子的话每次都会在重新创建movieWriter并将它设置为videoCamera的audioEncodingTarget时候，界面都会卡顿一下，这是什么原因呢？因为videoCamera默认是不录制声音的，而每次创建movieWriter的时候都用到了movieWriter.hasAudioTrack = YES;,吊用这个之后videoCamera会自动去添加声音输入源,准备一些数据，所以这个过程会导致界面卡顿一下？这该怎么办呢？如果你有进到videoCamera的头文件去看的话你会发现这么一个方法和它的注释</p>

<pre><code>//Add audio capture to the session. Adding inputs and outputs freezes 
//the capture session momentarily, so you can use this method to add 
//the audio inputs and outputs early, if you’re going to set the 
//audioEncodingTarget later. Returns YES is the audio inputs and 
//outputs were added, or NO if they had already been added.

-(BOOL)addAudioInputsAndOutputs;
</code></pre>

<p>注释的大意是:录制的时候添加声音,添加输入源和输出源会暂时会使录制暂时卡住,所以在要使用声音的情况下要先调用该方法来防止录制被卡住。这不刚好就解决了上面的这个问题吗？所以问题就迎刃而解了,因为没看到这个,走了不少弯路,浪费了好长时间。</p>

<p>关于分段录制,可能有这么一个需求就是所有片段都是存于一个文件中而不是录制完成后将各段合并到一个视频文件中。这两个东西或许会帮到你<a href="http://blog.csdn.net/whf727/article/details/18702643">分段录制的实现</a>,<a href="https://github.com/leanlyne/GPUImageExtend">GPUImageExtend</a>。前者是基于系统的分段录制的实现,后者是GPUImageMoiveWriter的一个子类。</p>

<h4>所见即所得</h4>

<p>在录制的时候,使用GPUImageView来显示,因为给GPUImageView设置的大小是320*320的,如果不设置它的填充模式(fillMode)它是默认使用kGPUImageFillModePreserveAspectRatio即保持长宽比,其余空白处使用背景色填充,如果要设置成方形就得使用kGPUImageFillModePreserveAspectRatioAndFill,但是这个时候问题又来了假设你是用的录制分辨率是960x540,显示的画面则只会显示中间的540x540的画面,这个时候如果movieWriter的size设置为540x540,则最后保存的视频是失真的因为960被压到了540，整个画面变扁了。这个时候有两种解决方案</p>

<ul>
<li>1.使用GPUImageCropFilter,通过设置其cropRegion来裁出中间540x540部分。关于cropRegion要注意它是一个CGRect,它对坐标系做了一个归一化处理,所以让所有的取值都在0.0~1.0范围内,比如960x540裁剪至中间540x540部分则cropRegion为(0,((960-540)/2)/960,1,540/960)</li>
<li>2.改变videoComposition的perferTransfom使其只显示中间的540x540。
这样就完成了所见即所得。</li>
</ul>


<p>关于GPUImage的实时滤镜添加或给已存在的视频添加滤镜,Demo都给出了详细过程,依葫芦画瓢即可。有一点要注意的是,在一些操作完成的时候注意removeTarget,还有就是在使用movieFile来播放已存在视频并添加滤镜的时候是没有声音的,这是这个库的一个缺陷,Github上有人提了这个<a href="https://github.com/BradLarson/GPUImage/issues/458">issue</a>和<a href="https://gist.github.com/pgodino/3819907">一些解决办法</a>。同时在用movieFile处理视频的时候在切换滤镜的时候最好先cancelProcessing不然会有黑屏或卡顿现象出现。同样如果你是用老版本的GPUImage的时候,可能会遇到第一帧是红色的现象,有人提出这个issue后,作者修复了这个bug,切换到最新版的时候就不会有这种情况发生。发生这种情况的原因是视频掉帧,导致音频和视频不同步。</p>

<h3>总结</h3>

<p>AVFoundation还是有很多东西去做深层次的挖掘,GPUImage也是一样,有了这个强大的库,解决一些事情节省了大量时间。这次仅仅是一个小小的尝试,对于很多东西都是浅尝则止,文中难免会有错误,欢迎在评论中指正。如果你在使用GPUImage和AVFoundation有什么好的心得或者对一些问题有相应的解决方案,不妨在评论中分享一下。</p>

<hr />

<p>版权声明：我已将本文在微信公众平台的发表权「独家代理」给 iOS开发（ iOSDevTip ） 微信公众号。扫下方二维码即可关注「iOS 开发」：</p>

<p><img src="http://images.90159.com/icon/iOSDevTip.jpg" alt="iOSDevTip" /></p>
]]></content>
  </entry>
  
</feed>
